{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c0b093d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/coop/drozda/torch-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 113.62 M params.\n",
      "Keeping EMAs of 308.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 3, 64, 64) = 12288 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "LatentDiffusion(\n",
      "  (model): DiffusionWrapper(\n",
      "    (diffusion_model): UNetModel(\n",
      "      (time_embed): Sequential(\n",
      "        (0): Linear(in_features=160, out_features=640, bias=True)\n",
      "        (1): SiLU()\n",
      "        (2): Linear(in_features=640, out_features=640, bias=True)\n",
      "      )\n",
      "      (input_blocks): ModuleList(\n",
      "        (0): TimestepEmbedSequential(\n",
      "          (0): Conv2d(6, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (1-2): 2 x TimestepEmbedSequential(\n",
      "          (0): ResBlock(\n",
      "            (in_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 160, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (h_upd): Identity()\n",
      "            (x_upd): Identity()\n",
      "            (emb_layers): Sequential(\n",
      "              (0): SiLU()\n",
      "              (1): Linear(in_features=640, out_features=160, bias=True)\n",
      "            )\n",
      "            (out_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 160, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "              (3): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (skip_connection): Identity()\n",
      "          )\n",
      "        )\n",
      "        (3): TimestepEmbedSequential(\n",
      "          (0): Downsample(\n",
      "            (op): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (4): TimestepEmbedSequential(\n",
      "          (0): ResBlock(\n",
      "            (in_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 160, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (h_upd): Identity()\n",
      "            (x_upd): Identity()\n",
      "            (emb_layers): Sequential(\n",
      "              (0): SiLU()\n",
      "              (1): Linear(in_features=640, out_features=320, bias=True)\n",
      "            )\n",
      "            (out_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (skip_connection): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (5): TimestepEmbedSequential(\n",
      "          (0): ResBlock(\n",
      "            (in_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (h_upd): Identity()\n",
      "            (x_upd): Identity()\n",
      "            (emb_layers): Sequential(\n",
      "              (0): SiLU()\n",
      "              (1): Linear(in_features=640, out_features=320, bias=True)\n",
      "            )\n",
      "            (out_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (skip_connection): Identity()\n",
      "          )\n",
      "        )\n",
      "        (6): TimestepEmbedSequential(\n",
      "          (0): Downsample(\n",
      "            (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (7-8): 2 x TimestepEmbedSequential(\n",
      "          (0): ResBlock(\n",
      "            (in_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (h_upd): Identity()\n",
      "            (x_upd): Identity()\n",
      "            (emb_layers): Sequential(\n",
      "              (0): SiLU()\n",
      "              (1): Linear(in_features=640, out_features=320, bias=True)\n",
      "            )\n",
      "            (out_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (skip_connection): Identity()\n",
      "          )\n",
      "        )\n",
      "        (9): TimestepEmbedSequential(\n",
      "          (0): Downsample(\n",
      "            (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (10): TimestepEmbedSequential(\n",
      "          (0): ResBlock(\n",
      "            (in_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (h_upd): Identity()\n",
      "            (x_upd): Identity()\n",
      "            (emb_layers): Sequential(\n",
      "              (0): SiLU()\n",
      "              (1): Linear(in_features=640, out_features=640, bias=True)\n",
      "            )\n",
      "            (out_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1): AttentionBlock(\n",
      "            (norm): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "            (qkv): Conv1d(640, 1920, kernel_size=(1,), stride=(1,))\n",
      "            (attention): QKVAttentionLegacy()\n",
      "            (proj_out): Conv1d(640, 640, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "        (11): TimestepEmbedSequential(\n",
      "          (0): ResBlock(\n",
      "            (in_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (h_upd): Identity()\n",
      "            (x_upd): Identity()\n",
      "            (emb_layers): Sequential(\n",
      "              (0): SiLU()\n",
      "              (1): Linear(in_features=640, out_features=640, bias=True)\n",
      "            )\n",
      "            (out_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (skip_connection): Identity()\n",
      "          )\n",
      "          (1): AttentionBlock(\n",
      "            (norm): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "            (qkv): Conv1d(640, 1920, kernel_size=(1,), stride=(1,))\n",
      "            (attention): QKVAttentionLegacy()\n",
      "            (proj_out): Conv1d(640, 640, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (middle_block): TimestepEmbedSequential(\n",
      "        (0): ResBlock(\n",
      "          (in_layers): Sequential(\n",
      "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "            (1): SiLU()\n",
      "            (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "          (h_upd): Identity()\n",
      "          (x_upd): Identity()\n",
      "          (emb_layers): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=640, out_features=640, bias=True)\n",
      "          )\n",
      "          (out_layers): Sequential(\n",
      "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "            (1): SiLU()\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "            (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "          (skip_connection): Identity()\n",
      "        )\n",
      "        (1): AttentionBlock(\n",
      "          (norm): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "          (qkv): Conv1d(640, 1920, kernel_size=(1,), stride=(1,))\n",
      "          (attention): QKVAttentionLegacy()\n",
      "          (proj_out): Conv1d(640, 640, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (2): ResBlock(\n",
      "          (in_layers): Sequential(\n",
      "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "            (1): SiLU()\n",
      "            (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "          (h_upd): Identity()\n",
      "          (x_upd): Identity()\n",
      "          (emb_layers): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=640, out_features=640, bias=True)\n",
      "          )\n",
      "          (out_layers): Sequential(\n",
      "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "            (1): SiLU()\n",
      "            (2): Dropout(p=0, inplace=False)\n",
      "            (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "          (skip_connection): Identity()\n",
      "        )\n",
      "      )\n",
      "      (output_blocks): ModuleList(\n",
      "        (0-1): 2 x TimestepEmbedSequential(\n",
      "          (0): ResBlock(\n",
      "            (in_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (h_upd): Identity()\n",
      "            (x_upd): Identity()\n",
      "            (emb_layers): Sequential(\n",
      "              (0): SiLU()\n",
      "              (1): Linear(in_features=640, out_features=640, bias=True)\n",
      "            )\n",
      "            (out_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1): AttentionBlock(\n",
      "            (norm): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "            (qkv): Conv1d(640, 1920, kernel_size=(1,), stride=(1,))\n",
      "            (attention): QKVAttentionLegacy()\n",
      "            (proj_out): Conv1d(640, 640, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "        (2): TimestepEmbedSequential(\n",
      "          (0): ResBlock(\n",
      "            (in_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (h_upd): Identity()\n",
      "            (x_upd): Identity()\n",
      "            (emb_layers): Sequential(\n",
      "              (0): SiLU()\n",
      "              (1): Linear(in_features=640, out_features=640, bias=True)\n",
      "            )\n",
      "            (out_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1): AttentionBlock(\n",
      "            (norm): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "            (qkv): Conv1d(640, 1920, kernel_size=(1,), stride=(1,))\n",
      "            (attention): QKVAttentionLegacy()\n",
      "            (proj_out): Conv1d(640, 640, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (2): Upsample(\n",
      "            (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (3): TimestepEmbedSequential(\n",
      "          (0): ResBlock(\n",
      "            (in_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (h_upd): Identity()\n",
      "            (x_upd): Identity()\n",
      "            (emb_layers): Sequential(\n",
      "              (0): SiLU()\n",
      "              (1): Linear(in_features=640, out_features=320, bias=True)\n",
      "            )\n",
      "            (out_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (4): TimestepEmbedSequential(\n",
      "          (0): ResBlock(\n",
      "            (in_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (h_upd): Identity()\n",
      "            (x_upd): Identity()\n",
      "            (emb_layers): Sequential(\n",
      "              (0): SiLU()\n",
      "              (1): Linear(in_features=640, out_features=320, bias=True)\n",
      "            )\n",
      "            (out_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (5): TimestepEmbedSequential(\n",
      "          (0): ResBlock(\n",
      "            (in_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (h_upd): Identity()\n",
      "            (x_upd): Identity()\n",
      "            (emb_layers): Sequential(\n",
      "              (0): SiLU()\n",
      "              (1): Linear(in_features=640, out_features=320, bias=True)\n",
      "            )\n",
      "            (out_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1): Upsample(\n",
      "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (6-7): 2 x TimestepEmbedSequential(\n",
      "          (0): ResBlock(\n",
      "            (in_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (h_upd): Identity()\n",
      "            (x_upd): Identity()\n",
      "            (emb_layers): Sequential(\n",
      "              (0): SiLU()\n",
      "              (1): Linear(in_features=640, out_features=320, bias=True)\n",
      "            )\n",
      "            (out_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (8): TimestepEmbedSequential(\n",
      "          (0): ResBlock(\n",
      "            (in_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 480, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Conv2d(480, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (h_upd): Identity()\n",
      "            (x_upd): Identity()\n",
      "            (emb_layers): Sequential(\n",
      "              (0): SiLU()\n",
      "              (1): Linear(in_features=640, out_features=320, bias=True)\n",
      "            )\n",
      "            (out_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (skip_connection): Conv2d(480, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1): Upsample(\n",
      "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (9): TimestepEmbedSequential(\n",
      "          (0): ResBlock(\n",
      "            (in_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 480, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Conv2d(480, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (h_upd): Identity()\n",
      "            (x_upd): Identity()\n",
      "            (emb_layers): Sequential(\n",
      "              (0): SiLU()\n",
      "              (1): Linear(in_features=640, out_features=160, bias=True)\n",
      "            )\n",
      "            (out_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 160, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "              (3): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (skip_connection): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (10-11): 2 x TimestepEmbedSequential(\n",
      "          (0): ResBlock(\n",
      "            (in_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Conv2d(320, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (h_upd): Identity()\n",
      "            (x_upd): Identity()\n",
      "            (emb_layers): Sequential(\n",
      "              (0): SiLU()\n",
      "              (1): Linear(in_features=640, out_features=160, bias=True)\n",
      "            )\n",
      "            (out_layers): Sequential(\n",
      "              (0): GroupNorm32(32, 160, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "              (2): Dropout(p=0, inplace=False)\n",
      "              (3): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "            (skip_connection): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (out): Sequential(\n",
      "        (0): GroupNorm32(32, 160, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(160, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (model_ema): LitEma()\n",
      "  (first_stage_model): VQModelInterface(\n",
      "    (encoder): Encoder(\n",
      "      (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (down): ModuleList(\n",
      "        (0): Module(\n",
      "          (block): ModuleList(\n",
      "            (0-1): 2 x ResnetBlock(\n",
      "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (attn): ModuleList()\n",
      "          (downsample): Downsample(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
      "          )\n",
      "        )\n",
      "        (1): Module(\n",
      "          (block): ModuleList(\n",
      "            (0): ResnetBlock(\n",
      "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (1): ResnetBlock(\n",
      "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (attn): ModuleList()\n",
      "          (downsample): Downsample(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "          )\n",
      "        )\n",
      "        (2): Module(\n",
      "          (block): ModuleList(\n",
      "            (0): ResnetBlock(\n",
      "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (nin_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (1): ResnetBlock(\n",
      "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (attn): ModuleList()\n",
      "        )\n",
      "      )\n",
      "      (mid): Module(\n",
      "        (block_1): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (attn_1): AttnBlock(\n",
      "          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (block_2): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "      (conv_out): Conv2d(512, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (decoder): Decoder(\n",
      "      (conv_in): Conv2d(3, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mid): Module(\n",
      "        (block_1): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (attn_1): AttnBlock(\n",
      "          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (block_2): ResnetBlock(\n",
      "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (up): ModuleList(\n",
      "        (0): Module(\n",
      "          (block): ModuleList(\n",
      "            (0): ResnetBlock(\n",
      "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (nin_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (1-2): 2 x ResnetBlock(\n",
      "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (attn): ModuleList()\n",
      "        )\n",
      "        (1): Module(\n",
      "          (block): ModuleList(\n",
      "            (0): ResnetBlock(\n",
      "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "              (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (nin_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (1-2): 2 x ResnetBlock(\n",
      "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (attn): ModuleList()\n",
      "          (upsample): Upsample(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (2): Module(\n",
      "          (block): ModuleList(\n",
      "            (0-2): 3 x ResnetBlock(\n",
      "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (attn): ModuleList()\n",
      "          (upsample): Upsample(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "      (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (loss): Identity()\n",
      "    (quantize): VectorQuantizer2(\n",
      "      (embedding): Embedding(8192, 3)\n",
      "    )\n",
      "    (quant_conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (post_quant_conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (cond_stage_model): Identity()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import h5py\n",
    "import yaml\n",
    "import torchvision.transforms  as T\n",
    "import numpy                   as np\n",
    "import matplotlib.pyplot       as plt\n",
    "from   torch.nn.functional import interpolate\n",
    "from   omegaconf           import OmegaConf\n",
    "from   pytorch_lightning   import Trainer\n",
    "\n",
    "from   ldm.util  import instantiate_from_config\n",
    "\n",
    "# Instantiate model from config YAML file\n",
    "config_path = \"ldm/yaml_config.yaml\"\n",
    "config      = OmegaConf.load(config_path)\n",
    "model       = instantiate_from_config(config.model)\n",
    "\n",
    "# Load checkpoint\n",
    "ckpt_path = \"model.ckpt\" # Unzip from https://ommer-lab.com/files/latent-diffusion/sr_bsr.zip\n",
    "sd        = torch.load(ckpt_path, map_location=\"cpu\")[\"state_dict\"]\n",
    "model.load_state_dict(sd, strict=False)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaac3053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device       = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model        = model.to(device)\n",
    "model.logvar = model.logvar.to(model.device)\n",
    "print(f\"model.device: {model.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bad3af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for super-resolution using pre-loaded tensors of HR and LR arrays.\n",
    "    Expects two tensors: \n",
    "      hr_arrays: shape (N, C, H_hr, W_hr) - e.g., (1000, 3, 256, 256)\n",
    "      lr_arrays: shape (N, C, H_lr, W_lr) - e.g., (1000, 3, 64, 64)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hr_arrays, lr_arrays):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hr_arrays: torch.Tensor of shape (N, C, H_hr, W_hr)\n",
    "            lr_arrays: torch.Tensor of shape (N, C, H_lr, W_lr)\n",
    "        \"\"\"\n",
    "        # Validate inputs\n",
    "        assert isinstance(hr_arrays, torch.Tensor), \"hr_arrays must be a torch.Tensor\"\n",
    "        assert isinstance(lr_arrays, torch.Tensor), \"lr_arrays must be a torch.Tensor\"\n",
    "        assert hr_arrays.ndim     == 4, f\"hr_arrays must be 4D tensor, got shape {hr_arrays.shape}\"\n",
    "        assert lr_arrays.ndim     == 4, f\"lr_arrays must be 4D tensor, got shape {lr_arrays.shape}\"\n",
    "        assert hr_arrays.shape[0] == lr_arrays.shape[0], f\"Batch size mismatch: HR {hr_arrays.shape[0]}, LR {lr_arrays.shape[0]}\"\n",
    "        assert hr_arrays.shape[1] == lr_arrays.shape[1], f\"Channel mismatch: HR {hr_arrays.shape[1]}, LR {lr_arrays.shape[1]}\"\n",
    "        \n",
    "        # Store references to the tensors\n",
    "        self.hr = hr_arrays\n",
    "        self.lr = lr_arrays\n",
    "        \n",
    "        # Store dataset size\n",
    "        self.num_samples = hr_arrays.shape[0]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a dictionary with keys 'image' (HR) and 'LR_image' (LR).\n",
    "        Note: The returned tensors are views, not copies, for memory efficiency.\n",
    "        \"\"\"\n",
    "        # Index into the batch dimension\n",
    "        hr_sample = self.hr[idx]  # Shape: (C, H_hr, W_hr)\n",
    "        lr_sample = self.lr[idx]  # Shape: (C, H_lr, W_lr)\n",
    "        \n",
    "        # Permute from (C, H, W) to (H, W, C)\n",
    "        hr_sample = hr_sample.permute(1, 2, 0)\n",
    "        lr_sample = lr_sample.permute(1, 2, 0)\n",
    "        \n",
    "        return {'image': hr_sample, 'LR_image': lr_sample}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "301d9bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JAX-CFD normalized data (range [-1,1])\n",
    "# See 'data/generate.ipynb'\n",
    "path          = 'data/data_normalized.h5'\n",
    "hr_data       = torch.from_numpy(h5py.File(path, 'r')['hr'][:])\n",
    "lr_data       = torch.from_numpy(h5py.File(path, 'r')['lr'][:])\n",
    "hr_tensor     = torch.stack([hr_data for _ in range(3)], 1)     # create RGB tensor from data\n",
    "lr_tensor     = torch.stack([lr_data for _ in range(3)], 1)     # create RGB tensor from data\n",
    "train_dataset = SRDataset(hr_tensor, lr_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c89e2d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/coop/drozda/torch-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set PyTorch DataLoader for training\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b43a85f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/scratch/coop/drozda/torch-env/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "/scratch/coop/drozda/torch-env/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "You are using a CUDA device ('NVIDIA A100-PCIE-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type             | Params | Mode  | FLOPs\n",
      "-----------------------------------------------------------------------\n",
      "0 | model             | DiffusionWrapper | 113 M  | train | 0    \n",
      "1 | model_ema         | LitEma           | 0      | train | 0    \n",
      "2 | first_stage_model | VQModelInterface | 55.3 M | eval  | 0    \n",
      "3 | cond_stage_model  | Identity         | 0      | eval  | 0    \n",
      "-----------------------------------------------------------------------\n",
      "113 M     Trainable params\n",
      "55.3 M    Non-trainable params\n",
      "168 M     Total params\n",
      "675.781   Total estimated model params size (MB)\n",
      "411       Modules in train mode\n",
      "175       Modules in eval mode\n",
      "0         Total Flops\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n",
      "/scratch/coop/drozda/torch-env/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:317: The number of training batches (16) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "/scratch/coop/drozda/torch-env/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:534: Found 175 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:08<00:00,  1.97it/s, v_num=12, train/loss_simple_step=0.0185, train/loss_vlb_step=0.000161, train/loss_step=0.0185, global_step=2047.0, train/loss_simple_epoch=0.0232, train/loss_vlb_epoch=0.000433, train/loss_epoch=0.0232]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=128` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:11<00:00,  1.35it/s, v_num=12, train/loss_simple_step=0.0185, train/loss_vlb_step=0.000161, train/loss_step=0.0185, global_step=2047.0, train/loss_simple_epoch=0.0232, train/loss_vlb_epoch=0.000433, train/loss_epoch=0.0232]\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "trainer = Trainer(\n",
    "    accelerator='auto',\n",
    "    max_epochs=128, # or your desired number\n",
    "    logger=True,    # TensorBoard by default\n",
    "    callbacks=[],   # Add ModelCheckpoint etc.\n",
    ")\n",
    "trainer.fit(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fceb294c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`weights_only` was not set, defaulting to `False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to model_tuned.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Save model checkpoint\n",
    "ckpt_tuned_path = \"model_tuned.ckpt\"\n",
    "trainer.save_checkpoint(ckpt_tuned_path)\n",
    "print(f\"Model saved to {ckpt_tuned_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaca7a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload model\n",
    "# model_tuned = instantiate_from_config(config.model)\n",
    "# sd_tuned    = torch.load(ckpt_tuned_path, map_location=\"cpu\")[\"state_dict\"]\n",
    "# model.load_state_dict(sd_tuned, strict=False)\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db23638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion-kolmogorov-flow-env",
   "language": "python",
   "name": "diffusion-kolmogorov-flow-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
